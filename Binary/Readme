This research presents an elegant feature ranking approach based on the probability density estimation to cope with these issues. The idea behind our approach, named Density Based Feature Selection (DBFS), is that features’ distributions over classes can bring significant benefits to feature selection algorithms. In other words, to explore the contribution of each attribute and assign it an appropriate rank, DBFS takes into account features’ corresponding distributions over all classes along with their correlations. To show the effectiveness of the presented approach, well-known feature selection metrics are implemented and compared with our approach across varieties of data sets
from microarray, mass spectrometry and text mining domains. Our theoretical analysis and experimental observations reveal that our approach is the method of choice by offering simple yet effective feature selection metric based on wellknown statistical evaluation measures.
